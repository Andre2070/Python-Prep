{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Con la clase creada en el módulo 7, tener en cuenta diferentes casos en que el código pudiera arrojar error. Por ejemplo, en la creación del objeto recibimos una lista de números enteros pero ¿qué pasa si se envía otro tipo de dato?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import herramientas as h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Se ha creado una lista vacía. Se esperaba una lista de núemeros enteros",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m h1 \u001b[39m=\u001b[39m h\u001b[39m.\u001b[39;49mHerramientas(\u001b[39m'\u001b[39;49m\u001b[39mHola\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\agude\\Desktop\\Python-Prep\\08 - Error Handling\\herramientas.py:5\u001b[0m, in \u001b[0;36mHerramientas.__init__\u001b[1;34m(self, lista_numeros)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[39mif\u001b[39;00m (\u001b[39mtype\u001b[39m(lista_numeros) \u001b[39m!=\u001b[39m \u001b[39mlist\u001b[39m):\n\u001b[0;32m      4\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlista \u001b[39m=\u001b[39m []\n\u001b[1;32m----> 5\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mSe ha creado una lista vacía. Se esperaba una lista de núemeros enteros\u001b[39m\u001b[39m'\u001b[39m)  \n\u001b[0;32m      6\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m      7\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlista \u001b[39m=\u001b[39m lista_numeros\n",
      "\u001b[1;31mValueError\u001b[0m: Se ha creado una lista vacía. Se esperaba una lista de núemeros enteros"
     ]
    }
   ],
   "source": [
    "h1 = h.Herramientas('Hola')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "h1 = h.Herramientas([2,3,5,6,2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) En la función que hace la conversión de grados, validar que los parámetros enviados sean los esperados, de no serlo, informar cuáles son los valores esperados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'herramientas' from 'c:\\\\Users\\\\agude\\\\Desktop\\\\Python-Prep\\\\08 - Error Handling\\\\herramientas.py'>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib #me recarga el módulo que estamos trayendo, para no reiniciar el kernel\n",
    "importlib.reload(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Los parametros de destino esperados son: ['celsius', 'kelvin', 'farenheit']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import herramientas as h\n",
    "h1 = h.Herramientas([2,3,5,6,2])\n",
    "h1.conversion_grados(1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[35.6, 37.4, 41.0, 42.8, 35.6]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h1.conversion_grados('celsius', 'farenheit')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Importar el modulo \"unittest\" y crear los siguientes casos de pruebas sobre la clase utilizada en el punto 2<br>\n",
    "Creacion del objeto incorrecta<br>\n",
    "Creacion correcta del objeto<br>\n",
    "Metodo valor_modal()<br>\n",
    "\n",
    "Se puede usar \"raise ValueError()\" en la creación de la clase para verificar el error. Investigar sobre esta funcionalidad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unittest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProbandoMiClase(unittest.TestCase):\n",
    "    \n",
    "    def test_crear_objeto1(self):\n",
    "        param = 'hola'\n",
    "        self.assertRaises(ValueError, h.Herramientas, param)\n",
    "        #self.failUnlessRaises(ValueError, h.Herramientas, param)\n",
    "\n",
    "    def test_crear_objeto2(self):\n",
    "        param = [1,2,2,5]\n",
    "        h1 = h.Herramientas(param)\n",
    "        self.assertEqual(h1.lista, param)\n",
    "\n",
    "    def test_valor_modal(self):\n",
    "        lis = [1,2,1,3]\n",
    "        h1 = h.Herramientas(lis)\n",
    "        moda, veces = h1.valor_modal(False)\n",
    "        moda = [moda]\n",
    "        moda.append(veces)\n",
    "        resultado = [1, 2]\n",
    "        self.assertEqual(moda, resultado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_crear_objeto1 (__main__.ProbandoMiClase.test_crear_objeto1) ... ok\n",
      "test_crear_objeto2 (__main__.ProbandoMiClase.test_crear_objeto2) ... ok\n",
      "test_valor_modal (__main__.ProbandoMiClase.test_valor_modal) ... ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 3 tests in 0.007s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.main.TestProgram at 0x1368b9eff50>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unittest.main(argv=[''], verbosity=2, exit=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) Probar una creación incorrecta y visualizar la salida del \"raise\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Se ha creado una lista vacía. Se esperaba una lista de núemeros enteros",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[35], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m h2 \u001b[39m=\u001b[39m h\u001b[39m.\u001b[39;49mHerramientas(\u001b[39m'\u001b[39;49m\u001b[39malgo\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\agude\\Desktop\\Python-Prep\\08 - Error Handling\\herramientas.py:5\u001b[0m, in \u001b[0;36mHerramientas.__init__\u001b[1;34m(self, lista_numeros)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[39mif\u001b[39;00m (\u001b[39mtype\u001b[39m(lista_numeros) \u001b[39m!=\u001b[39m \u001b[39mlist\u001b[39m): \u001b[39m#se le agregó\u001b[39;00m\n\u001b[0;32m      4\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlista \u001b[39m=\u001b[39m [] \u001b[39m# para el punto uno\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mSe ha creado una lista vacía. Se esperaba una lista de núemeros enteros\u001b[39m\u001b[39m'\u001b[39m) \u001b[39m# raise es paara levantar el error\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m      7\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlista \u001b[39m=\u001b[39m lista_numeros\n",
      "\u001b[1;31mValueError\u001b[0m: Se ha creado una lista vacía. Se esperaba una lista de núemeros enteros"
     ]
    }
   ],
   "source": [
    "h2 = h.Herramientas('algo')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6) Agregar casos de pruebas para el método verifica_primos() realizando el cambio en la clase, para que devuelva una lista de True o False en función de que el elemento en la posisicón sea o no primo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProbandoMiClase2(unittest.TestCase):\n",
    "\n",
    "    def test_verifica_primos1(self):\n",
    "        lis = [2,3,8,10,13]\n",
    "        h1 = h.Herramientas(lis)\n",
    "        primos = h1.verifica_primo()\n",
    "        primos_esperado = [True, True, False, False, True]\n",
    "        self.assertEqual(primos, primos_esperado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'herramientas' from 'c:\\\\Users\\\\agude\\\\Desktop\\\\Python-Prep\\\\08 - Error Handling\\\\herramientas.py'>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_crear_objeto1 (__main__.ProbandoMiClase.test_crear_objeto1) ... ok\n",
      "test_crear_objeto2 (__main__.ProbandoMiClase.test_crear_objeto2) ... ok\n",
      "test_valor_modal (__main__.ProbandoMiClase.test_valor_modal) ... ok\n",
      "test_verifica_primos1 (__main__.ProbandoMiClase2.test_verifica_primos1) ... ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.005s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.main.TestProgram at 0x136876073d0>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unittest.main(argv=[''], verbosity=2, exit=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7) Agregar casos de pruebas para el método conversion_grados()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProbandoMiClase3(unittest.TestCase):\n",
    "\n",
    "    def test_verifica_conversion1(self):\n",
    "        lis = [2,3,8,10,13]\n",
    "        h1 = h.Herramientas(lis)\n",
    "        grados = h1.conversion_grados('celsius','farenheit')\n",
    "        grados_esperado = [35.6, 37.4, 46.4, 50.0, 55.4]\n",
    "        self.assertEqual(grados, grados_esperado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'herramientas' from 'c:\\\\Users\\\\agude\\\\Desktop\\\\Python-Prep\\\\08 - Error Handling\\\\herramientas.py'>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_crear_objeto1 (__main__.ProbandoMiClase.test_crear_objeto1) ... ok\n",
      "test_crear_objeto2 (__main__.ProbandoMiClase.test_crear_objeto2) ... ok\n",
      "test_valor_modal (__main__.ProbandoMiClase.test_valor_modal) ... ok\n",
      "test_verifica_primos1 (__main__.ProbandoMiClase2.test_verifica_primos1) ... ok\n",
      "test_verifica_conversion1 (__main__.ProbandoMiClase3.test_verifica_conversion1) ... ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.008s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.main.TestProgram at 0x1368c846490>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unittest.main(argv=[''], verbosity=2, exit=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8) Agregar casos de pruebas para el método factorial()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProbandoMiClase4(unittest.TestCase):\n",
    "\n",
    "    def test_verifica_factorial(self):\n",
    "        lis = [2,3,8,10,13]\n",
    "        h1 = h.Herramientas(lis)\n",
    "        factorial = h1.factorial()\n",
    "        factorial_esperado = [2, 6, 40320, 3628800, 6227020800]\n",
    "        self.assertEqual(factorial, factorial_esperado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'herramientas' from 'c:\\\\Users\\\\agude\\\\Desktop\\\\Python-Prep\\\\08 - Error Handling\\\\herramientas.py'>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_crear_objeto1 (__main__.ProbandoMiClase.test_crear_objeto1) ... ok\n",
      "test_crear_objeto2 (__main__.ProbandoMiClase.test_crear_objeto2) ... ok\n",
      "test_valor_modal (__main__.ProbandoMiClase.test_valor_modal) ... ok\n",
      "test_verifica_primos1 (__main__.ProbandoMiClase2.test_verifica_primos1) ... ok\n",
      "test_verifica_conversion1 (__main__.ProbandoMiClase3.test_verifica_conversion1) ... ok\n",
      "test_verifica_factorial (__main__.ProbandoMiClase4.test_verifica_factorial) ... ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 6 tests in 0.009s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.main.TestProgram at 0x1368bc81010>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unittest.main(argv=[''], verbosity=2, exit=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
